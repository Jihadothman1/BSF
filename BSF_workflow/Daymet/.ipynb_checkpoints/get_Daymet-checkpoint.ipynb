{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Download Daymet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daymet provides gridded meteorological data for North American at 1km spatial resolution with daily timestep from 1980 ~ present. [website](https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1328) and [user guide](https://daac.ornl.gov/DAYMET/guides/Daymet_V3_CFMosaics.html)\n",
    "\n",
    "Available variables:\n",
    "\n",
    "| Variable | Description (units) |\n",
    "| ---- | ---- |\n",
    "| tmax | Daily maximum 2-meter air temperature (°C) |\n",
    "| tmin | Daily minimum 2-meter air temperature (°C) |\n",
    "| prcp | Daily total precipitation (mm/day) |\n",
    "| srad | Incident shortwave radiation flux density (W/m2) |\n",
    "| vp   | Water vapor pressure (Pa) |\n",
    "| swe  | Snow water equivalent (kg/m2) |\n",
    "| dayl | Duration of the daylight period (seconds) |\n",
    "\n",
    "Notes:\n",
    " - The Daymet calendar is based on a standard calendar year. All Daymet years, including leap years, have 1 - 365 days. For leap years, the Daymet database includes leap day (February 29) and values for December 31 are discarded from leap years to maintain a 365-day year.\n",
    " \n",
    " - DayMet's incident shortwave radiation is the \"daylit\" radiation.  To get the daily average radiation, one must multiply by daylit fraction, given by dayl / 86400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "import watershed_workflow\n",
    "import watershed_workflow.ui\n",
    "import watershed_workflow.sources.manager_daymet\n",
    "import watershed_workflow.daymet\n",
    "import watershed_workflow.io\n",
    "\n",
    "watershed_workflow.ui.setup_logging(1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_shapefile = 'Coweeta/input_data/BSF_USGS_UTM_12.shp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 21:38:00,363 - root - INFO: \n",
      "2023-06-08 21:38:00,364 - root - INFO: Loading shapes\n",
      "2023-06-08 21:38:00,365 - root - INFO: ------------------------------\n",
      "2023-06-08 21:38:00,365 - root - INFO: Loading file: 'Coweeta/input_data/coweeta_basin.shp'\n",
      "2023-06-08 21:38:00,454 - root - INFO: ... found 1 shapes\n",
      "2023-06-08 21:38:00,455 - root - INFO: Converting to shapely\n",
      "2023-06-08 21:38:00,460 - root - INFO: crs: epsg:26917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(273971.0911428096, 3878839.6361173145, 279140.9150949494, 3883953.7853134344)\n",
      "5169.823952139821 5114.149196119979\n"
     ]
    }
   ],
   "source": [
    "crs, watershed = watershed_workflow.get_split_form_shapes(watershed_shapefile)\n",
    "logging.info(f'crs: {crs}')\n",
    "\n",
    "bounds = watershed.exterior().bounds\n",
    "print(bounds)\n",
    "print(bounds[2] - bounds[0], bounds[3] - bounds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "returned raw data has `dim(nband, ncol, nrow)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the end date to 2021 to get the recent data by keeping the same format\n",
    "startdate = \"2000-1-1\"\n",
    "# startdate = \"1980-1-1\"\n",
    "enddate = \"2021-1-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FileManagerDaymet' object has no attribute 'get_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# setting vars = None to download all available variables\u001b[39;00m\n\u001b[1;32m      2\u001b[0m source \u001b[38;5;241m=\u001b[39m watershed_workflow\u001b[38;5;241m.\u001b[39msources\u001b[38;5;241m.\u001b[39mmanager_daymet\u001b[38;5;241m.\u001b[39mFileManagerDaymet()\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m(bounds, crs, startdate, enddate)\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m source\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FileManagerDaymet' object has no attribute 'get_data'"
     ]
    }
   ],
   "source": [
    "# setting vars = None to download all available variables\n",
    "source = watershed_workflow.sources.manager_daymet.FileManagerDaymet()\n",
    "data = source.get_data(bounds, crs, startdate, enddate)\n",
    "data = source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproject Daymet CRS\n",
    "\n",
    "Reproject daymet CRS to the same as the watershed. This is necessary if watershed meshes are using watershed CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = watershed_workflow.warp.state(data, dst_crs=crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot Daymet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivar = 'tmax'\n",
    "islice = 100\n",
    "daymet_crs = watershed_workflow.crs.daymet_crs()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = watershed_workflow.plot.get_ax(daymet_crs, fig, 1, 2, 1)\n",
    "ax2 = watershed_workflow.plot.get_ax(crs, fig, 1, 2, 2)\n",
    "\n",
    "watershed_ext_daymet = watershed_workflow.warp.shply(watershed.exterior(),\n",
    "                                                     crs, daymet_crs)\n",
    "watershed_workflow.plot.raster(data[ivar].profile, data[ivar].data[islice,:,:], ax1)\n",
    "watershed_workflow.plot.shply(watershed_ext_daymet, daymet_crs, ax=ax1, color='r')\n",
    "\n",
    "watershed_workflow.plot.raster(data_new[ivar].profile, data_new[ivar].data[islice,:,:], ax2)\n",
    "watershed_workflow.plot.hucs(watershed, crs, ax=ax2, color='r')\n",
    "\n",
    "ax1.set_title(\"Raw Daymet\")\n",
    "ax2.set_title(\"Reprojected Daymet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save daymet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to HDF5\n",
    "\n",
    "Write raw daymet data to a single HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(data_new.collections) == 1)\n",
    "met_data = data_new.collections[0]\n",
    "\n",
    "filename = os.path.join('Coweeta','output_data', 'watershed_daymet-raw.h5')\n",
    "watershed_workflow.io.write_dataset_to_hdf5(\n",
    "    filename,\n",
    "    met_data, \n",
    "    watershed_workflow.daymet.getAttributes(bounds, startdate, enddate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to ATS format\n",
    "\n",
    "This will write daymet in a format that ATS can read. E.g., this will partition precipitation into rain and snow, convert vapor pressure to relative humidity, get mean air temperature and so on.\n",
    "\n",
    "- dout has dims of `(ntime, nrow, ncol)` or `(ntime, ny, nx)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_data_ats = watershed_workflow.daymet.daymet_to_daily_averages(met_data)\n",
    "\n",
    "filename = os.path.join('Coweeta', 'output_data', 'watershed_daymet-ats.h5')\n",
    "watershed_workflow.io.write_dataset_to_hdf5(\n",
    "    filename,\n",
    "    met_data_ats.collections[0],\n",
    "    watershed_workflow.daymet.getAttributes(bounds, startdate, enddate))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (watershed_workflow)",
   "language": "python",
   "name": "watershed_workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
